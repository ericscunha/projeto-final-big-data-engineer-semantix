{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final Spark - Semantix Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autor: [Eric Cunha](https://linkedin.com/in/ericscunha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nível Básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Enviar os dados para o hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Criando estrutura de diretórios do projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -mkdir -p /user/eric/projeto_spark/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Copiando os arquivos do namenode para o hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdfs dfs -put /input/covid19/* /user/eric/projeto_spark/data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "-rw-r--r--   3 root supergroup   62492959 2022-08-04 19:23 /user/eric/projeto_spark/data/HIST_PAINEL_COVIDBR_2020_Parte1_06jul2021.csv\r\n",
      "-rw-r--r--   3 root supergroup   76520681 2022-08-04 19:23 /user/eric/projeto_spark/data/HIST_PAINEL_COVIDBR_2020_Parte2_06jul2021.csv\r\n",
      "-rw-r--r--   3 root supergroup   91120916 2022-08-04 19:23 /user/eric/projeto_spark/data/HIST_PAINEL_COVIDBR_2021_Parte1_06jul2021.csv\r\n",
      "-rw-r--r--   3 root supergroup    3046774 2022-08-04 19:23 /user/eric/projeto_spark/data/HIST_PAINEL_COVIDBR_2021_Parte2_06jul2021.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Verificando se os dados foram carregados corretamente\n",
    "!hdfs dfs -ls /user/eric/projeto_spark/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---------+-----+------+--------------+---------------+-------------------+---------+----------------+--------------+----------+---------------+-----------+----------------+---------------------+----------------------+\n",
      "|regiao|estado|municipio|coduf|codmun|codRegiaoSaude|nomeRegiaoSaude|               data|semanaEpi|populacaoTCU2019|casosAcumulado|casosNovos|obitosAcumulado|obitosNovos|Recuperadosnovos|emAcompanhamentoNovos|interior/metropolitana|\n",
      "+------+------+---------+-----+------+--------------+---------------+-------------------+---------+----------------+--------------+----------+---------------+-----------+----------------+---------------------+----------------------+\n",
      "|Brasil|  null|     null|   76|  null|          null|           null|2020-02-25 00:00:00|        9|       210147125|             0|         0|              0|          0|            null|                 null|                  null|\n",
      "|Brasil|  null|     null|   76|  null|          null|           null|2020-02-26 00:00:00|        9|       210147125|             1|         1|              0|          0|            null|                 null|                  null|\n",
      "|Brasil|  null|     null|   76|  null|          null|           null|2020-02-27 00:00:00|        9|       210147125|             1|         0|              0|          0|            null|                 null|                  null|\n",
      "|Brasil|  null|     null|   76|  null|          null|           null|2020-02-28 00:00:00|        9|       210147125|             1|         0|              0|          0|            null|                 null|                  null|\n",
      "|Brasil|  null|     null|   76|  null|          null|           null|2020-02-29 00:00:00|        9|       210147125|             2|         1|              0|          0|            null|                 null|                  null|\n",
      "+------+------+---------+-----+------+--------------+---------------+-------------------+---------+----------------+--------------+----------+---------------+-----------+----------------+---------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Carregandos os dados\n",
    "df_covid = spark.read.csv(\"/user/eric/projeto_spark/data/*.csv\", sep=\";\", header=True, inferSchema=True)\n",
    "df_covid.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- regiao: string (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- coduf: integer (nullable = true)\n",
      " |-- codmun: integer (nullable = true)\n",
      " |-- codRegiaoSaude: integer (nullable = true)\n",
      " |-- nomeRegiaoSaude: string (nullable = true)\n",
      " |-- data: timestamp (nullable = true)\n",
      " |-- semanaEpi: integer (nullable = true)\n",
      " |-- populacaoTCU2019: integer (nullable = true)\n",
      " |-- casosAcumulado: decimal(10,0) (nullable = true)\n",
      " |-- casosNovos: integer (nullable = true)\n",
      " |-- obitosAcumulado: integer (nullable = true)\n",
      " |-- obitosNovos: integer (nullable = true)\n",
      " |-- Recuperadosnovos: integer (nullable = true)\n",
      " |-- emAcompanhamentoNovos: integer (nullable = true)\n",
      " |-- interior/metropolitana: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando a estrutura dos dados\n",
    "df_covid.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+---------+----------------+--------------+----------+-----------+---------------+----------------+---------------------+\n",
      "|               data|regiao|estado|municipio|populacaoTCU2019|casosAcumulado|casosNovos|obitosNovos|obitosAcumulado|Recuperadosnovos|emAcompanhamentoNovos|\n",
      "+-------------------+------+------+---------+----------------+--------------+----------+-----------+---------------+----------------+---------------------+\n",
      "|2020-02-25 00:00:00| Norte|    AM|     null|         4144597|             0|         0|          0|              0|            null|                 null|\n",
      "|2020-02-25 00:00:00| Norte|    PA|     null|         8602865|             0|         0|          0|              0|            null|                 null|\n",
      "|2020-02-25 00:00:00|Brasil|  null|     null|       210147125|             0|         0|          0|              0|            null|                 null|\n",
      "|2020-02-25 00:00:00| Norte|    AC|     null|          881935|             0|         0|          0|              0|            null|                 null|\n",
      "|2020-02-25 00:00:00| Norte|    RO|     null|         1777225|             0|         0|          0|              0|            null|                 null|\n",
      "+-------------------+------+------+---------+----------------+--------------+----------+-----------+---------------+----------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizando apenas campos chaves\n",
    "df_covid.select('data',\n",
    "                'regiao', \n",
    "                'estado',\n",
    "                'municipio',\n",
    "                'populacaoTCU2019',\n",
    "                'casosAcumulado',\n",
    "                'casosNovos',\n",
    "                'obitosNovos', \n",
    "                'obitosAcumulado', \n",
    "                'Recuperadosnovos', \n",
    "                'emAcompanhamentoNovos')\\\n",
    "        .sort(col('data').asc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [X] Atribui zero aos campos Nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notnull = df_covid.na.fill({'estado': 0, 'municipio': 0, 'Recuperadosnovos': 0, 'emAcompanhamentoNovos': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [X] Tratar campo data e campo casosAcumulado para integer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_final = df_notnull.withColumn(\"data\", to_date(\"data\", \"dd/MM/yyyy\"))\\\n",
    "                            .withColumn(\"casosAcumulado\", col(\"casosAcumulado\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Otimizar todos os dados do hdfs para uma tabela Hive particionada por município."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# verifica os databases existentes\n",
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cria o database projetofinal\n",
    "spark.sql(\"create database projetofinal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_final.write.mode(\"overwrite\").partitionBy(\"municipio\").saveAsTable(\"projetofinal.covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Criar as 3 vizualizações pelo Spark com os dados enviados para o HDFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados da tabela Hive \"covid\"\n",
    "table_covid = spark.read.table(\"projetofinal.covid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [X] Visualização de Casos Recuperados e em Acompanhamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------------+\n",
      "|Recuperadosnovos|emAcompanhamentoNovos|\n",
      "+----------------+---------------------+\n",
      "|        17262646|              1317658|\n",
      "+----------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "painel_recuperados_acompanhamento = table_covid.filter(\"regiao='Brasil'\")\\\n",
    "                                               .select(\"Recuperadosnovos\", \"emAcompanhamentoNovos\")\\\n",
    "                                               .agg(max(\"Recuperadosnovos\").alias(\"Recuperadosnovos\"),\\\n",
    "                                                    max(\"emAcompanhamentoNovos\").alias(\"emAcompanhamentoNovos\"))\n",
    "\n",
    "painel_recuperados_acompanhamento.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [X] Visualização de Casos Confirmados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função calcula a incidencia por habitantes\n",
    "def calcula_incidencia(numero_casos, populacao, taxa_habitantes):\n",
    "    return format_number(((numero_casos * taxa_habitantes)/populacao), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica o número de casos novos pela data mais recente\n",
    "df_casos_novos = table_covid.select(\"casosNovos\").filter(\"regiao='Brasil'\").sort(col(\"data\").desc())\n",
    "casos_novos = df_casos_novos.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(62504='casosNovos')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casos_novos(\"casosNovos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# painel de casos confirmados com calculo de incidência por 100 mil/hab\n",
    "painel_casos_confirmados = table_covid.filter(\"regiao='Brasil'\")\\\n",
    "                                .select(\"casosAcumulado\",\"populacaoTCU2019\")\\\n",
    "                                .agg(max(\"casosAcumulado\").alias(\"casosAcumulado\"),\\\n",
    "                                     max(\"populacaoTCU2019\").alias(\"populacaoTCU2019\"))\\\n",
    "                                .withColumn(\"casosNovos\", lit(casos_novos[0]))\\\n",
    "                                .withColumn(\"incidencia\",\n",
    "                                           calcula_incidencia(col(\"casosAcumulado\").cast(FloatType()),\n",
    "                                                             col(\"populacaoTCU2019\").cast(FloatType()),\n",
    "                                                             100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------+\n",
      "|casosAcumulado|casosNovos|Incidencia|\n",
      "+--------------+----------+----------+\n",
      "|      18855015|     62504|  8,972.29|\n",
      "+--------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "painel_casos_confirmados = painel_casos_confirmados.select(\"casosAcumulado\", \"casosNovos\", \"Incidencia\")\n",
    "painel_casos_confirmados.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [X] Visualização de Óbitos Confirmados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função que calcula a letalidade\n",
    "def calcula_letalidade(numero_casos, numero_obitos):\n",
    "    return format_number(((numero_obitos * 100)/numero_casos), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função que calcula a mortalidade por habitantes\n",
    "def calcula_mortalidade(numero_obitos, populacao, taxa_habitantes):\n",
    "    return format_number(((numero_obitos * taxa_habitantes)/populacao), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(1780='obitosNovos')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifica o número de casos novos pela data mais recente\n",
    "df_obitos_novos = table_covid.select(\"obitosNovos\").filter(\"regiao='Brasil'\").sort(col(\"data\").desc())\n",
    "obitos_novos = df_obitos_novos.first()\n",
    "obitos_novos(\"obitosNovos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# painel de casos confirmados com calculo de mortalidade por 100 mil/hab\n",
    "painel_obitos = table_covid.filter(\"regiao='Brasil'\")\\\n",
    "                                .select(\"obitosAcumulado\",\"populacaoTCU2019\", \"casosAcumulado\")\\\n",
    "                                .agg(max(\"obitosAcumulado\").alias(\"obitosAcumulado\"),\\\n",
    "                                     max(\"casosAcumulado\").alias(\"casosAcumulado\"),\\\n",
    "                                     max(\"populacaoTCU2019\").alias(\"populacaoTCU2019\"))\\\n",
    "                                .withColumn(\"obitosNovos\", lit(obitos_novos[0]))\\\n",
    "                                .withColumn(\"mortalidade\",\n",
    "                                           calcula_mortalidade(col(\"obitosAcumulado\").cast(FloatType()),\n",
    "                                                               col(\"populacaoTCU2019\").cast(FloatType()),\n",
    "                                                               100000))\\\n",
    "                                .withColumn(\"letalidade\",\n",
    "                                           calcula_letalidade(col(\"casosAcumulado\").cast(FloatType()),\n",
    "                                                               col(\"obitosAcumulado\").cast(FloatType())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+-----------+----------+\n",
      "|obitosAcumulado|obitosNovos|mortalidade|letalidade|\n",
      "+---------------+-----------+-----------+----------+\n",
      "|         526892|       1780|     250.73|      2.79|\n",
      "+---------------+-----------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "painel_obitos = painel_obitos.select(\"obitosAcumulado\", \"obitosNovos\", \"mortalidade\", \"letalidade\")\n",
    "painel_obitos.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Salvar a primeira visualização como tabela Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "painel_recuperados_acompanhamento.write.mode(\"overwrite\").saveAsTable(\"projetofinal.casos_recuperados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------------+\n",
      "|Recuperadosnovos|emAcompanhamentoNovos|\n",
      "+----------------+---------------------+\n",
      "|        17262646|              1317658|\n",
      "+----------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"projetofinal.casos_recuperados\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|    Recuperadosnovos|                 int|   null|\n",
      "|emAcompanhamentoN...|                 int|   null|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|            Database|        projetofinal|       |\n",
      "|               Table|   casos_recuperados|       |\n",
      "|               Owner|                root|       |\n",
      "|        Created Time|Mon Aug 08 19:01:...|       |\n",
      "|         Last Access|Thu Jan 01 00:00:...|       |\n",
      "|          Created By|         Spark 2.4.1|       |\n",
      "|                Type|             MANAGED|       |\n",
      "|            Provider|             parquet|       |\n",
      "|    Table Properties|[transient_lastDd...|       |\n",
      "|            Location|file:/mnt/noteboo...|       |\n",
      "|       Serde Library|org.apache.hadoop...|       |\n",
      "|         InputFormat|org.apache.hadoop...|       |\n",
      "|        OutputFormat|org.apache.hadoop...|       |\n",
      "|  Storage Properties|[serialization.fo...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"desc formatted projetofinal.casos_recuperados\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Salvar a segunda visualização com formato parquet e compressão snappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando como parquet e compressão snappy com saveAsTable\n",
    "painel_casos_confirmados.write.mode(\"overwrite\")\\\n",
    "                              .option(\"compression\", \"snappy\")\\\n",
    "                              .format(\"parquet\")\\\n",
    "                              .saveAsTable(\"projetofinal.casos_confirmados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------+\n",
      "|casosAcumulado|casosNovos|Incidencia|\n",
      "+--------------+----------+----------+\n",
      "|      18855015|     62504|  8,972.29|\n",
      "+--------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table(\"projetofinal.casos_confirmados\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|      casosAcumulado|                 int|   null|\n",
      "|          casosNovos|                 int|   null|\n",
      "|          Incidencia|              string|   null|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|            Database|        projetofinal|       |\n",
      "|               Table|   casos_confirmados|       |\n",
      "|               Owner|                root|       |\n",
      "|        Created Time|Mon Aug 08 19:18:...|       |\n",
      "|         Last Access|Thu Jan 01 00:00:...|       |\n",
      "|          Created By|         Spark 2.4.1|       |\n",
      "|                Type|             MANAGED|       |\n",
      "|            Provider|             parquet|       |\n",
      "|    Table Properties|[transient_lastDd...|       |\n",
      "|            Location|file:/mnt/noteboo...|       |\n",
      "|       Serde Library|org.apache.hadoop...|       |\n",
      "|         InputFormat|org.apache.hadoop...|       |\n",
      "|        OutputFormat|org.apache.hadoop...|       |\n",
      "|  Storage Properties|[serialization.fo...|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"desc extended projetofinal.casos_confirmados\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   1 root root          0 2022-08-08 19:18 file:///mnt/notebooks/spark-warehouse/projetofinal.db/casos_confirmados/_SUCCESS\r\n",
      "-rw-r--r--   1 root root        906 2022-08-08 19:18 file:///mnt/notebooks/spark-warehouse/projetofinal.db/casos_confirmados/part-00000-faa4b1d4-01cf-49d3-ba63-1d846039b090-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "# Visualizando os arquivos\n",
    "!hdfs dfs -ls file:/mnt/notebooks/spark-warehouse/projetofinal.db/casos_confirmados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando no namenode como parquet e compressão snappy\n",
    "painel_casos_confirmados.write.mode(\"overwrite\")\\\n",
    "                              .option(\"compression\", \"snappy\")\\\n",
    "                              .parquet(\"/user/eric/projeto_spark/data/casos_confirmados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   2 root supergroup          0 2022-08-08 19:22 /user/eric/projeto_spark/data/casos_confirmados/_SUCCESS\r\n",
      "-rw-r--r--   2 root supergroup        906 2022-08-08 19:22 /user/eric/projeto_spark/data/casos_confirmados/part-00000-32432bb0-95b7-489b-8d5d-b548e9c1baf7-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "# Visualizando os arquivos\n",
    "!hdfs dfs -ls /user/eric/projeto_spark/data/casos_confirmados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Salvar a terceira visualização em um tópico no Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o tópico no kafka (key, value)\n",
    "painel_obitos.selectExpr(\"CONCAT(1) AS key\", \"to_json(struct(*)) AS value\")\\\n",
    "            .write\\\n",
    "            .format(\"kafka\")\\\n",
    "            .option(\"kafka.bootstrap.servers\",\"kafka:9092\")\\\n",
    "            .option(\"topic\",\"obitos-confirmados-br\")\\\n",
    "            .option(\"value\", \"1\")\\\n",
    "            .option(\"checkpointLocation\",\"/user/eric/projeto_spark/data/kafka/checkpoint\")\\\n",
    "            .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o tópico para conferência\n",
    "topic_obitos = spark.read\\\n",
    "                    .format(\"kafka\")\\\n",
    "                    .option(\"kafka.bootstrap.servers\",\"kafka:9092\")\\\n",
    "                    .option(\"subscribe\",\"obitos-confirmados-br\")\\\n",
    "                    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------------------------------------------------------------+\n",
      "|key|value                                                                                   |\n",
      "+---+----------------------------------------------------------------------------------------+\n",
      "|1  |{\"obitosAcumulado\":526892,\"obitosNovos\":1780,\"mortalidade\":\"250.73\",\"letalidade\":\"2.79\"}|\n",
      "+---+----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Formata o tópico para visualização\n",
    "view_topic = topic_obitos.select(col(\"key\").cast(\"string\"), col(\"value\").cast(\"string\"))\n",
    "view_topic.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Criar a visualização pelo Spark com os dados enviados para o HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona os dados de acordo com a apresentação solicitada\n",
    "painel_sintese = table_covid.groupBy([\"regiao\", \"estado\"])\\\n",
    "                            .agg(max(\"casosAcumulado\").alias(\"Casos\"),\n",
    "                                 max(\"obitosAcumulado\").alias(\"Obitos\"),\n",
    "                                 max(\"populacaoTCU2019\").alias(\"populacaoTCU2019\"),\n",
    "                                 max(\"data\").alias(\"Atualizacao\"))\\\n",
    "                            .withColumn(\"incidenciaPor100Mil\",\n",
    "                                           calcula_incidencia(col(\"Casos\").cast(FloatType()),\n",
    "                                                             col(\"populacaoTCU2019\").cast(FloatType()),\n",
    "                                                             100000))\\\n",
    "                            .withColumn(\"mortalidadePor100Mil\",\n",
    "                                           calcula_mortalidade(col(\"Obitos\").cast(FloatType()),\n",
    "                                                               col(\"populacaoTCU2019\").cast(FloatType()),\n",
    "                                                               100000))\\\n",
    "                            .drop(\"populacaoTCU2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------+------+-------------------+--------------------+-----------+\n",
      "|      regiao|estado|   Casos|Obitos|incidenciaPor100Mil|mortalidadePor100Mil|Atualizacao|\n",
      "+------------+------+--------+------+-------------------+--------------------+-----------+\n",
      "|      Brasil|     0|18855015|526892|           8,972.29|              250.73| 2021-07-06|\n",
      "|Centro-Oeste|    MS|  339323|  8400|          12,210.32|              302.27| 2021-07-06|\n",
      "|Centro-Oeste|    GO|  686433| 19485|           9,780.54|              277.63| 2021-07-06|\n",
      "|Centro-Oeste|    DF|  434708|  9322|          14,416.89|              309.16| 2021-07-06|\n",
      "|Centro-Oeste|    MT|  456155| 12000|          13,091.10|              344.39| 2021-07-06|\n",
      "|    Nordeste|    AL|  220793|  5450|           6,615.80|              163.30| 2021-07-06|\n",
      "|    Nordeste|    MA|  322052|  9190|           4,551.86|              129.89| 2021-07-06|\n",
      "|    Nordeste|    PB|  402175|  8724|          10,009.02|              217.12| 2021-07-06|\n",
      "|    Nordeste|    PE|  561505| 17953|           5,875.28|              187.85| 2021-07-06|\n",
      "|    Nordeste|    BA| 1141612| 24428|           7,675.70|              164.24| 2021-07-06|\n",
      "|    Nordeste|    PI|  299084|  6662|           9,137.28|              203.53| 2021-07-06|\n",
      "|    Nordeste|    RN|  347248|  6853|           9,901.98|              195.42| 2021-07-06|\n",
      "|    Nordeste|    CE|  894678| 22791|           9,797.09|              249.57| 2021-07-06|\n",
      "|    Nordeste|    SE|  266590|  5773|          11,597.44|              251.14| 2021-07-06|\n",
      "|       Norte|    RR|  113758|  1763|          18,779.35|              291.04| 2021-07-06|\n",
      "|       Norte|    AP|  118066|  1857|          13,960.23|              219.57| 2021-07-06|\n",
      "|       Norte|    AM|  405066| 13349|           9,773.35|              322.08| 2021-07-06|\n",
      "|       Norte|    AC|   85997|  1760|           9,750.95|              199.56| 2021-07-06|\n",
      "|       Norte|    PA|  557708| 15624|           6,482.82|              181.61| 2021-07-06|\n",
      "|       Norte|    RO|  252024|  6226|          14,180.76|              350.32| 2021-07-06|\n",
      "|       Norte|    TO|  200243|  3266|          12,731.09|              207.65| 2021-07-06|\n",
      "|     Sudeste|    ES|  523115| 11582|          13,017.18|              288.21| 2021-07-06|\n",
      "|     Sudeste|    SP| 3809222|130389|           8,295.52|              283.95| 2021-07-06|\n",
      "|     Sudeste|    RJ|  970268| 56192|           5,619.87|              325.47| 2021-07-06|\n",
      "|     Sudeste|    MG| 1836198| 47148|           8,674.08|              222.72| 2021-07-06|\n",
      "|         Sul|    RS| 1235914| 31867|          10,863.04|              280.09| 2021-07-06|\n",
      "|         Sul|    PR| 1308643| 31692|          11,445.23|              277.17| 2021-07-06|\n",
      "|         Sul|    SC| 1066484| 17146|          14,885.07|              239.31| 2021-07-06|\n",
      "+------------+------+--------+------+-------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "painel_sintese.select(\"regiao\", \n",
    "                      \"estado\", \n",
    "                      \"Casos\", \n",
    "                      \"Obitos\", \n",
    "                      \"incidenciaPor100Mil\", \n",
    "                      \"mortalidadePor100Mil\", \n",
    "                      \"Atualizacao\")\\\n",
    "              .sort(col(\"regiao\").asc()).show(28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Salvar a visualização do exercício 6 em um tópico no Elastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Criar um dashboard no Elastic para visualização dos novos dados enviados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
